#!/usr/bin/env python3
"""
Script Ä‘á»ƒ táº£i trÆ°á»›c cÃ¡c model Depth Anything V2 tá»« Hugging Face Hub
"""

import os
import sys
import time
import shutil
import traceback
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
import torch
from huggingface_hub import snapshot_download
from tqdm import tqdm

# Äá»‹nh nghÄ©a cÃ¡c model cáº§n táº£i
MODELS_TO_DOWNLOAD = {
    # Metric Models cho Indoor (theo cáº¥u hÃ¬nh hiá»‡n táº¡i cá»§a báº¡n)
    "indoor_large": "depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf",
    "indoor_base": "depth-anything/Depth-Anything-V2-Metric-Indoor-Base-hf", 
    "indoor_small": "depth-anything/Depth-Anything-V2-Metric-Indoor-Small-hf",
    
    # Náº¿u báº¡n muá»‘n thÃªm Outdoor models
    # "outdoor_large": "depth-anything/Depth-Anything-V2-Metric-Outdoor-Large-hf",
    # "outdoor_base": "depth-anything/Depth-Anything-V2-Metric-Outdoor-Base-hf",
    # "outdoor_small": "depth-anything/Depth-Anything-V2-Metric-Outdoor-Small-hf",
    
    # Náº¿u báº¡n muá»‘n thÃªm Regular models
    # "regular_large": "depth-anything/Depth-Anything-V2-Large-hf",
    # "regular_base": "depth-anything/Depth-Anything-V2-Base-hf",
    # "regular_small": "depth-anything/Depth-Anything-V2-Small-hf",
}

def download_model(model_name: str, model_id: str, force_download: bool = False):
    """
    Táº£i má»™t model tá»« Hugging Face Hub
    
    Args:
        model_name: TÃªn model Ä‘á»ƒ hiá»ƒn thá»‹
        model_id: ID model trÃªn Hugging Face Hub
        force_download: Ã‰p buá»™c táº£i láº¡i náº¿u Ä‘Ã£ cÃ³
    """
    print(f"\n{'='*60}")
    print(f"Äang táº£i model: {model_name}")
    print(f"Model ID: {model_id}")
    print(f"{'='*60}")
    
    try:
        # Táº£i processor trÆ°á»›c
        print("ğŸ”„ Äang táº£i Image Processor...")
        processor = AutoImageProcessor.from_pretrained(
            model_id, 
            force_download=force_download
        )
        print("âœ… Image Processor Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
        
        # Táº£i model
        print("ğŸ”„ Äang táº£i Model...")
        
        # Sá»­ dá»¥ng torch.float32 Ä‘á»ƒ trÃ¡nh lá»—i vá»›i má»™t sá»‘ GPU
        model = AutoModelForDepthEstimation.from_pretrained(
            model_id,
            torch_dtype=torch.float32,  # Sá»­ dá»¥ng float32 Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n
            force_download=force_download
        )
        print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
        
        # Kiá»ƒm tra kÃ­ch thÆ°á»›c model
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š Sá»‘ lÆ°á»£ng tham sá»‘: {total_params:,}")
        
        # Kiá»ƒm tra memory footprint
        model_size_mb = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)
        print(f"ğŸ’¾ KÃ­ch thÆ°á»›c model: {model_size_mb:.1f} MB")
        
        # Test nhanh Ä‘á»ƒ Ä‘áº£m báº£o model hoáº¡t Ä‘á»™ng
        print("ğŸ§ª Äang kiá»ƒm tra model...")
        
        # Táº¡o áº£nh test giáº£ tá»« numpy
        import numpy as np
        from PIL import Image
        
        # Táº¡o áº£nh RGB test 224x224
        test_image_np = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        test_image_pil = Image.fromarray(test_image_np)
        
        # Xá»­ lÃ½ vá»›i processor
        test_processed = processor(
            images=test_image_pil, 
            return_tensors="pt"
        )
        
        # Thá»±c hiá»‡n inference test
        with torch.no_grad():
            test_output = model(**test_processed)
            
        print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra vÃ  hoáº¡t Ä‘á»™ng tá»‘t!")
        print(f"ğŸ“ KÃ­ch thÆ°á»›c output: {test_output.predicted_depth.shape}")
        
        # Dá»n dáº¹p memory
        del model, processor, test_image_np, test_image_pil, test_processed, test_output
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i khi táº£i model {model_name}:")
        print(f"   {str(e)}")
        traceback.print_exc()
        return False

def check_system_requirements():
    """Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng"""
    print("ğŸ” Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng...")
    
    # Kiá»ƒm tra Python version
    python_version = sys.version_info
    print(f"ğŸ Python version: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # Kiá»ƒm tra torch
    try:
        print(f"ğŸ”¥ PyTorch version: {torch.__version__}")
        print(f"ğŸ–¥ï¸  CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"ğŸ® CUDA device: {torch.cuda.get_device_name(0)}")
            print(f"ğŸ’¾ CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    except Exception as e:
        print(f"âŒ PyTorch lá»—i: {e}")
        return False
    
    # Kiá»ƒm tra transformers
    try:
        import transformers
        print(f"ğŸ¤— Transformers version: {transformers.__version__}")
    except ImportError:
        print("âŒ Transformers chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
        return False
    
    # Kiá»ƒm tra disk space
    cache_dir = os.path.expanduser("~/.cache/huggingface")
    if os.path.exists(cache_dir):
        total, used, free = shutil.disk_usage(cache_dir)
        print(f"ğŸ’½ Disk space available: {free / 1024**3:.1f} GB")
        if free < 10 * 1024**3:  # 10GB
            print("âš ï¸  Cáº£nh bÃ¡o: Ãt hÆ¡n 10GB dung lÆ°á»£ng trá»‘ng!")
    
    return True

def main():
    print("ğŸš€ Báº¯t Ä‘áº§u táº£i cÃ¡c model Depth Anything V2")
    print("="*60)
    
    # Kiá»ƒm tra yÃªu cáº§u há»‡ thá»‘ng
    if not check_system_requirements():
        print("âŒ YÃªu cáº§u há»‡ thá»‘ng khÃ´ng Ä‘Ã¡p á»©ng!")
        return
    
    # Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n force download khÃ´ng
    force_download = False
    response = input("\nğŸ¤” Báº¡n cÃ³ muá»‘n táº£i láº¡i cÃ¡c model Ä‘Ã£ cÃ³ sáºµn khÃ´ng? (y/N): ").strip().lower()
    if response in ['y', 'yes', 'cÃ³']:
        force_download = True
    
    # Báº¯t Ä‘áº§u táº£i models
    success_count = 0
    total_count = len(MODELS_TO_DOWNLOAD)
    
    for model_name, model_id in MODELS_TO_DOWNLOAD.items():
        success = download_model(model_name, model_id, force_download)
        if success:
            success_count += 1
        
        # Pause giá»¯a cÃ¡c láº§n táº£i Ä‘á»ƒ giáº£m táº£i server
        if model_name != list(MODELS_TO_DOWNLOAD.keys())[-1]:  # KhÃ´ng pause á»Ÿ láº§n cuá»‘i
            print("\nâ¸ï¸  Táº¡m dá»«ng 5 giÃ¢y trÆ°á»›c khi táº£i model tiáº¿p...")
            time.sleep(5)
    
    # TÃ³m táº¯t káº¿t quáº£
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Káº¾T QUáº¢ Tá»”NG QUAN")
    print(f"{'='*60}")
    print(f"âœ… ThÃ nh cÃ´ng: {success_count}/{total_count} models")
    print(f"âŒ Tháº¥t báº¡i: {total_count - success_count}/{total_count} models")
    
    if success_count == total_count:
        print("\nğŸ‰ Táº¥t cáº£ models Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
        print("ğŸ’¡ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y use_tensorrt_example.py mÃ  khÃ´ng cáº§n táº£i model online.")
        
        print("\nğŸ“‹ CÃ¡c model Ä‘Ã£ táº£i:")
        for model_name, model_id in MODELS_TO_DOWNLOAD.items():
            print(f"   â€¢ {model_name}: {model_id}")
            
        print("\nğŸ› ï¸  CÃ¡ch sá»­ dá»¥ng:")
        print("   # Sá»­ dá»¥ng Large model (máº·c Ä‘á»‹nh)")
        print("   python use_tensorrt_example.py")
        print("   ")
        print("   # Sá»­ dá»¥ng Base model")
        print("   set DEPTH_MODEL=base && python use_tensorrt_example.py")
        print("   ")
        print("   # Sá»­ dá»¥ng Small model (nhanh nháº¥t)")
        print("   set DEPTH_MODEL=small && python use_tensorrt_example.py")
        
    else:
        print(f"\nâš ï¸  Má»™t sá»‘ models khÃ´ng táº£i Ä‘Æ°á»£c. Vui lÃ²ng kiá»ƒm tra láº¡i káº¿t ná»‘i máº¡ng vÃ  thá»­ láº¡i.")
    
    print(f"\nğŸ“ Models Ä‘Æ°á»£c lÆ°u táº¡i: {os.path.expanduser('~/.cache/huggingface/transformers')}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ÄÃ£ há»§y bá» quÃ¡ trÃ¬nh táº£i!")
    except Exception as e:
        print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {str(e)}")
        traceback.print_exc()