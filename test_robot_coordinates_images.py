"""
Test Robot Coordinates v·ªõi ·∫£nh tƒ©nh
Script ƒë·ªÉ test chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t·ª´ camera sang robot v·ªõi t·ª´ng ·∫£nh
"""
import os
import cv2
import numpy as np
from pathlib import Path
import json
from datetime import datetime

# Import c√°c module c·∫ßn thi·∫øt
from detection.utils.robot_coordinate_transform import RobotCoordinateTransform
from detection.utils.camera_calibration import CameraCalibration
from detection.utils.tensorrt_yolo import YOLOTensorRT


class ImageRobotCoordinateTest:
    """Class test t·ªça ƒë·ªô robot v·ªõi ·∫£nh tƒ©nh."""
    
    def __init__(self, model_path: str = "best.engine"):
        """
        Kh·ªüi t·∫°o test pipeline.
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n t·ªõi model YOLO
        """
        try:
            # Kh·ªüi t·∫°o YOLO model
            print("[ImageTest] ƒêang kh·ªüi t·∫°o YOLO model...")
            self.yolo_model = YOLOTensorRT(model_path)
            
            # Kh·ªüi t·∫°o robot coordinate transformer
            print("[ImageTest] ƒêang kh·ªüi t·∫°o robot coordinate transformer...")
            self.robot_transformer = RobotCoordinateTransform()
            
            # Kh·ªüi t·∫°o camera calibration (cho depth n·∫øu c√≥)
            print("[ImageTest] ƒêang kh·ªüi t·∫°o camera calibration...")
            self.camera_calibration = CameraCalibration()
            
            print("‚úÖ [ImageTest] Kh·ªüi t·∫°o th√†nh c√¥ng!")
            
            # Validation transformation
            validation_result = self.robot_transformer.validate_transformation()
            print(f"üìä [ImageTest] ƒê·ªô ch√≠nh x√°c transformation - Mean error: {validation_result['mean_error']:.4f}")
            
        except Exception as e:
            print(f"‚ùå [ImageTest] L·ªói kh·ªüi t·∫°o: {e}")
            raise
    
    def process_single_image(self, image_path: str, show_result: bool = True, save_result: bool = False):
        """
        X·ª≠ l√Ω m·ªôt ·∫£nh v√† tr·∫£ v·ªÅ t·ªça ƒë·ªô robot.
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n t·ªõi ·∫£nh
            show_result: C√≥ hi·ªÉn th·ªã k·∫øt qu·∫£ kh√¥ng
            save_result: C√≥ l∆∞u k·∫øt qu·∫£ kh√¥ng
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ detection v√† t·ªça ƒë·ªô robot
        """
        print(f"\n{'='*60}")
        print(f"üîç ƒêang x·ª≠ l√Ω: {os.path.basename(image_path)}")
        print(f"{'='*60}")
        
        # Load ·∫£nh
        image = cv2.imread(image_path)
        if image is None:
            print(f"‚ùå Kh√¥ng th·ªÉ load ·∫£nh: {image_path}")
            return None
        
        print(f"üì∏ K√≠ch th∆∞·ªõc ·∫£nh: {image.shape[1]}x{image.shape[0]}")
        
        try:
            # 1. Ch·∫°y YOLO detection
            print("üîç ƒêang ch·∫°y YOLO detection...")
            detection_result = self.yolo_model.detect(image)
            
            if not detection_result or not detection_result.get('bounding_boxes'):
                print("‚ùå Kh√¥ng ph√°t hi·ªán object n√†o!")
                if show_result:
                    cv2.imshow(f"Result - {os.path.basename(image_path)}", image)
                    cv2.waitKey(0)
                return {'image_path': image_path, 'detections': [], 'robot_coordinates': []}
            
            bboxes = detection_result.get('bounding_boxes', [])
            scores = detection_result.get('scores', [])
            classes = detection_result.get('classes', [])
            
            print(f"‚úÖ Ph√°t hi·ªán {len(bboxes)} object(s)")
            
            # 2. Chuy·ªÉn ƒë·ªïi format detection ƒë·ªÉ t∆∞∆°ng th√≠ch
            detection_results = []
            for i, bbox in enumerate(bboxes):
                x1, y1, x2, y2 = bbox
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                conf = scores[i] if i < len(scores) else 0.0
                cls_id = classes[i] if i < len(classes) else 0
                
                detection_result = {
                    'bbox': [x1, y1, x2, y2],
                    'center': [center_x, center_y],
                    'confidence': conf,
                    'class': f'class_{int(cls_id)}',  # T·∫°m th·ªùi d√πng class_id
                    'class_id': int(cls_id)
                }
                detection_results.append(detection_result)
            
            # 3. Chuy·ªÉn ƒë·ªïi sang robot coordinates
            print("üîÑ ƒêang chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô robot...")
            robot_results = self.robot_transformer.transform_detection_results(detection_results)
            
            # 4. T√≠nh t·ªça ƒë·ªô 3D n·∫øu c√≥ depth (gi·∫£ ƒë·ªãnh depth = 2.0m cho test)
            test_depth = 2.0  # Depth gi·∫£ ƒë·ªãnh cho test
            
            # 5. Chu·∫©n b·ªã k·∫øt qu·∫£
            final_results = []
            
            for i, result in enumerate(robot_results, 1):
                if 'center_robot' in result:
                    robot_coord = result['center_robot']
                    center_cam = result['center']
                    
                    # T√≠nh t·ªça ƒë·ªô 3D v·ªõi camera calibration
                    X_3d, Y_3d, Z_3d = self.camera_calibration.pixel_to_3d(
                        center_cam[0], center_cam[1], test_depth
                    )
                    
                    object_result = {
                        'id': i,
                        'class': result.get('class', 'unknown'),
                        'confidence': round(result.get('confidence', 0.0), 3),
                        'camera_coordinates': {
                            'pixel_x': int(center_cam[0]),
                            'pixel_y': int(center_cam[1])
                        },
                        'robot_coordinates': {
                            'x': round(robot_coord[0], 2),  # Robot X (mm ho·∫∑c m)
                            'y': round(robot_coord[1], 2),  # Robot Y (mm ho·∫∑c m)
                            'z': round(test_depth, 2)       # Depth (m)
                        },
                        'camera_3d_coordinates': {
                            'X': round(X_3d, 3),  # Camera coordinate X (m)
                            'Y': round(Y_3d, 3),  # Camera coordinate Y (m)
                            'Z': round(Z_3d, 3)   # Camera coordinate Z (m)
                        },
                        'bbox_camera': result.get('bbox', []),
                        'bbox_robot': result.get('bbox_robot', [])
                    }
                    
                    final_results.append(object_result)
                    
                    # In k·∫øt qu·∫£
                    print(f"\nüìç Object {i} ({object_result['class']}):")
                    print(f"   Confidence: {object_result['confidence']}")
                    print(f"   Camera pixel: ({object_result['camera_coordinates']['pixel_x']}, {object_result['camera_coordinates']['pixel_y']})")
                    print(f"   ‚û°Ô∏è  Robot coordinates: X={object_result['robot_coordinates']['x']}, Y={object_result['robot_coordinates']['y']}, Z={object_result['robot_coordinates']['z']}")
                    print(f"   üìê Camera 3D: X={object_result['camera_3d_coordinates']['X']}, Y={object_result['camera_3d_coordinates']['Y']}, Z={object_result['camera_3d_coordinates']['Z']}")
            
            # 6. Hi·ªÉn th·ªã k·∫øt qu·∫£ tr√™n ·∫£nh
            if show_result:
                result_image = self._draw_results_on_image(image.copy(), final_results)
                cv2.imshow(f"Result - {os.path.basename(image_path)}", result_image)
                print(f"\nüí° Nh·∫•n ph√≠m b·∫•t k·ª≥ ƒë·ªÉ ti·∫øp t·ª•c, 's' ƒë·ªÉ l∆∞u ·∫£nh, 'q' ƒë·ªÉ tho√°t...")
                key = cv2.waitKey(0) & 0xFF
                
                if key == ord('s'):
                    save_path = f"result_{os.path.basename(image_path)}"
                    cv2.imwrite(save_path, result_image)
                    print(f"üíæ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: {save_path}")
                elif key == ord('q'):
                    cv2.destroyAllWindows()
                    return None
            
            # 7. L∆∞u k·∫øt qu·∫£ JSON n·∫øu c·∫ßn
            if save_result:
                self._save_result_json(image_path, final_results)
            
            return {
                'image_path': image_path,
                'image_shape': image.shape,
                'detections': detection_results,
                'robot_coordinates': final_results,
                'total_objects': len(final_results)
            }
            
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω ·∫£nh: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _draw_results_on_image(self, image, results):
        """V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh."""
        for result in results:
            # L·∫•y th√¥ng tin
            pixel_coord = (result['camera_coordinates']['pixel_x'], 
                          result['camera_coordinates']['pixel_y'])
            robot_coord = result['robot_coordinates']
            bbox = result.get('bbox_camera', [])
            
            # V·∫Ω bounding box n·∫øu c√≥
            if bbox and len(bbox) >= 4:
                cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), 
                            (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)
            
            # V·∫Ω center point
            cv2.circle(image, pixel_coord, 8, (0, 0, 255), -1)
            cv2.circle(image, pixel_coord, 12, (255, 255, 255), 2)
            
            # V·∫Ω th√¥ng tin text
            y_offset = 0
            texts = [
                f"ID: {result['id']} ({result['class']})",
                f"Conf: {result['confidence']:.2f}",
                f"Robot: X={robot_coord['x']}, Y={robot_coord['y']}",
                f"Z={robot_coord['z']}m"
            ]
            
            for text in texts:
                text_pos = (pixel_coord[0] + 15, pixel_coord[1] - 10 + y_offset)
                
                # V·∫Ω background cho text
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
                cv2.rectangle(image, 
                            (text_pos[0] - 2, text_pos[1] - text_size[1] - 2),
                            (text_pos[0] + text_size[0] + 2, text_pos[1] + 2),
                            (0, 0, 0), -1)
                
                # V·∫Ω text
                cv2.putText(image, text, text_pos, cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (255, 255, 0), 1)
                y_offset += 20
        
        # V·∫Ω th√¥ng tin t·ªïng quan
        info_text = f"Total objects: {len(results)}"
        cv2.putText(image, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                   0.8, (255, 255, 255), 2)
        
        return image
    
    def _save_result_json(self, image_path, results):
        """L∆∞u k·∫øt qu·∫£ th√†nh file JSON."""
        result_data = {
            'image_path': image_path,
            'timestamp': datetime.now().isoformat(),
            'total_objects': len(results),
            'objects': results
        }
        
        json_filename = f"result_{os.path.splitext(os.path.basename(image_path))[0]}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ JSON: {json_filename}")


def quick_test_single_image():
    """Test nhanh v·ªõi 1 ·∫£nh."""
    print("üîç QUICK TEST - TEST V·ªöI 1 ·∫¢NH")
    
    # Kh·ªüi t·∫°o tester
    tester = ImageRobotCoordinateTest()
    
    # Test v·ªõi ·∫£nh ƒë·∫ßu ti√™n trong th∆∞ m·ª•c
    test_image = "test_result/image_1.jpg"
    
    if os.path.exists(test_image):
        print(f"üì∏ ƒêang test v·ªõi: {test_image}")
        result = tester.process_single_image(test_image, show_result=True, save_result=True)
        
        if result and result['robot_coordinates']:
            print(f"\nüéØ K·∫æT QU·∫¢ T·ªîNG H·ª¢P:")
            for obj in result['robot_coordinates']:
                robot_coord = obj['robot_coordinates']
                print(f"   {obj['class']} ‚Üí Robot: X={robot_coord['x']}, Y={robot_coord['y']}, Z={robot_coord['z']}")
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh test: {test_image}")


def test_multiple_images():
    """Test v·ªõi nhi·ªÅu ·∫£nh."""
    print("üîç TEST V·ªöI NHI·ªÄU ·∫¢NH")
    
    # Kh·ªüi t·∫°o tester
    tester = ImageRobotCoordinateTest()
    
    # Test v·ªõi 3 ·∫£nh ƒë·∫ßu ti√™n
    test_images = [
        "images_pallets/image_1.jpg",
        "images_pallets/image_2.jpg", 
        "images_pallets/image_3.jpg"
    ]
    
    all_coordinates = []
    
    for i, image_path in enumerate(test_images, 1):
        if os.path.exists(image_path):
            print(f"\n{'='*20} ·∫¢NH {i} {'='*20}")
            result = tester.process_single_image(image_path, show_result=False, save_result=False)
            
            if result and result['robot_coordinates']:
                for obj in result['robot_coordinates']:
                    robot_coord = obj['robot_coordinates']
                    coord_info = {
                        'image': os.path.basename(image_path),
                        'object_id': obj['id'],
                        'class': obj['class'],
                        'confidence': obj['confidence'],
                        'x': robot_coord['x'],
                        'y': robot_coord['y'],
                        'z': robot_coord['z']
                    }
                    all_coordinates.append(coord_info)
                    print(f"üéØ {obj['class']} (ID{obj['id']}) ‚Üí Robot: X={robot_coord['x']}, Y={robot_coord['y']}, Z={robot_coord['z']}")
    
    # T√≥m t·∫Øt t·∫•t c·∫£ t·ªça ƒë·ªô
    print(f"\n{'='*60}")
    print(f"üìä T√ìM T·∫ÆT T·∫§T C·∫¢ T·ªåA ƒê·ªò ROBOT:")
    print(f"{'='*60}")
    
    for coord in all_coordinates:
        print(f"{coord['image']:15s} | {coord['class']:8s} | X={coord['x']:8.2f} | Y={coord['y']:8.2f} | Z={coord['z']:6.2f} | Conf={coord['confidence']:.2f}")


if __name__ == "__main__":
    print("ü§ñ ROBOT COORDINATE TEST V·ªöI ·∫¢NH Tƒ®NH")
    print("="*50)
    
    print("\nüìã CH·ªåN KI·ªÇU TEST:")
    print("1. Quick test v·ªõi 1 ·∫£nh (c√≥ hi·ªÉn th·ªã)")
    print("2. Test v·ªõi 3 ·∫£nh (ch·ªâ in t·ªça ƒë·ªô)")
    print("3. Test manual (nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh)")
    
    choice = input("\nüëâ Ch·ªçn (1-3): ").strip()
    
    try:
        if choice == "1":
            quick_test_single_image()
        elif choice == "2":
            test_multiple_images()
        elif choice == "3":
            image_path = input("üìÅ Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: ").strip()
            if os.path.exists(image_path):
                tester = ImageRobotCoordinateTest()
                tester.process_single_image(image_path, show_result=True, save_result=True)
            else:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
    
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        cv2.destroyAllWindows() 